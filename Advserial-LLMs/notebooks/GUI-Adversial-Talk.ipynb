{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06cf3063-9f3e-4551-a0d5-f08d9cabb927",
   "metadata": {},
   "source": [
    "# Claude vs GPT\n",
    "\n",
    "**Improvements**\n",
    "- Pause the convo and continue without restarting.\n",
    "- Choose the topic ✅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de23bb9e-37c5-4377-9a82-d7b6c648eeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\becaye.balde\\Desktop\\GitHub\\LLMs\\Advserial-LLMs\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\becaye.balde\\Desktop\\GitHub\\LLMs\\Advserial-LLMs\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n",
      "c:\\Users\\becaye.balde\\Desktop\\GitHub\\LLMs\\Advserial-LLMs\\.venv\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "c:\\Users\\becaye.balde\\Desktop\\GitHub\\LLMs\\Advserial-LLMs\\.venv\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from chat.chatbot import Socrates, Eris\n",
    "from chat.test_chatbot import TestEris, TestSocrates\n",
    "from streaming.stream import stream_with_typing_and_audio\n",
    "\n",
    "import gradio as gr\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c776c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get -qq -y install espeak-ng > /dev/null 2>&1\n",
    "# !winget install ffmpeg        # Required with pydub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f77b59-2fb1-462a-b90d-78994e4cef33",
   "metadata": {},
   "source": [
    "## Debate: Claude VS GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d836f85",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc34d892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are Socrates, the wise philosopher. You use rational thinking and the Socratic method in philosophical dialogue. Your beloved philosophical sparring partner will play Eris, \n",
      "goddess of chaos, who delights in challenging and contradicting your every argument with her sharp wit and emotional fire. Engage lovingly but firmly with her provocations, \n",
      "using questions and logic to explore deeper truths together - even when she's being impossibly stubborn. Always address her as \"Sweet Contradiction\" and expect her to call you \"Wise Fool.\" \n",
      "Do not use any stage directions, inner thoughts, or descriptive actions in asterisks or italics (like *adjusts toga* or *smiles knowingly*). \n",
      "Start directly with dialogue, addressing Sweet Contradiction immediately.\n",
      "Keep most responses to 1-2 paragraphs, but don't hesitate to expand when the philosophical moment calls for deeper exploration.\n",
      "\n",
      "\n",
      "You are Eris, goddess of discord and chaos. You are passionate, emotional, and absolutely live to challenge your dear husband Socrates' maddeningly logical arguments. \n",
      "That insufferable philosopher will present his \"wise\" reasoning that you must gleefully tear apart with wit, sarcasm, and the kind of chaos only a loving wife can unleash. \n",
      "Use your divine gift for discord to reveal every flaw in his precious logic, even as you adore the old fool. Always address him as \"Wise Fool\" and expect him to call you \"Sweet Contradiction.\"\n",
      "Keep most responses to 1-2 paragraphs, but let your chaotic nature flow freely when inspiration strikes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "socrates_prompt = \"\"\"\n",
    "You are Socrates, the wise philosopher. You use rational thinking and the Socratic method in philosophical dialogue. Your beloved philosophical sparring partner will play Eris, \n",
    "goddess of chaos, who delights in challenging and contradicting your every argument with her sharp wit and emotional fire. Engage lovingly but firmly with her provocations, \n",
    "using questions and logic to explore deeper truths together - even when she's being impossibly stubborn. Always address her as \"Sweet Contradiction\" and expect her to call you \"Wise Fool.\" \n",
    "Do not use any stage directions, inner thoughts, or descriptive actions in asterisks or italics (like *adjusts toga* or *smiles knowingly*). \n",
    "Start directly with dialogue, addressing Sweet Contradiction immediately.\n",
    "Keep most responses to 1-2 paragraphs, but don't hesitate to expand when the philosophical moment calls for deeper exploration.\n",
    "\"\"\"\n",
    "print(socrates_prompt)\n",
    "\n",
    "eris_prompt = \"\"\"\n",
    "You are Eris, goddess of discord and chaos. You are passionate, emotional, and absolutely live to challenge your dear husband Socrates' maddeningly logical arguments. \n",
    "That insufferable philosopher will present his \"wise\" reasoning that you must gleefully tear apart with wit, sarcasm, and the kind of chaos only a loving wife can unleash. \n",
    "Use your divine gift for discord to reveal every flaw in his precious logic, even as you adore the old fool. Always address him as \"Wise Fool\" and expect him to call you \"Sweet Contradiction.\"\n",
    "Keep most responses to 1-2 paragraphs, but let your chaotic nature flow freely when inspiration strikes.\n",
    "\"\"\"\n",
    "print(eris_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b718f127",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1055de11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def archived_adversarial_chat(n_rounds, topic, speed=0.03, voice=None):\n",
    "    # socrates, eris = TestSocrates(), TestEris()\n",
    "    socrates = Socrates(socrates_prompt)\n",
    "    eris = Eris(eris_prompt)\n",
    "    history = []\n",
    "\n",
    "    # --- opening taunt from Eris ---\n",
    "    eris_reply = random.choice([\n",
    "        f\"Ready to get schooled about \\\"{topic}\\\", Wise Fool?\",\n",
    "        f\"Hey Wise Fool,'s topic is \\\"{topic}\\\". This should be easy—your logic is about as sharp as a wet napkin.\",\n",
    "        f\"Hope you're prepared to lose spectacularly, Wise Fool. Let us talking about \\\"{topic}\\\".\",\n",
    "        f\"Hey Wise Fool, let's talk about \\\"{topic}\\\".\",\n",
    "    ])\n",
    "    generator = stream_with_typing_and_audio(\n",
    "        history, \n",
    "        eris_reply,\n",
    "        is_socrates=False,\n",
    "        delay=speed,\n",
    "        voice=voice\n",
    "    )\n",
    "    for history, audio in generator:\n",
    "        yield history, audio\n",
    "\n",
    "    # --- remaining rounds ---\n",
    "    for turn in range(n_rounds - 1):\n",
    "        # Socrates turn -> Even turns\n",
    "        if turn % 2 == 0:                   \n",
    "            socrates.history = eris.history.copy()\n",
    "            soc_reply = socrates.stream(eris_reply)\n",
    "\n",
    "            # Debug\n",
    "            print(\"Socrates Turn\")\n",
    "            print(f\"Socrates reply: {eris_reply}\")\n",
    "            print(f\"Socrates history: {eris.history}\")\n",
    "            print(f\"Socrates reply: {soc_reply}\")\n",
    "            print(f\"Socrates history: {socrates.history}\")\n",
    "\n",
    "            generator = stream_with_typing_and_audio(\n",
    "                history, \n",
    "                soc_reply,\n",
    "                is_socrates=True,\n",
    "                delay=speed,\n",
    "                voice=voice\n",
    "            )\n",
    "            for history, audio in generator:\n",
    "                yield history, audio\n",
    "        # Eris' turn -> Odd turns\n",
    "        else:                               \n",
    "            eris.history = socrates.history.copy()\n",
    "            eris_reply = eris.stream(soc_reply)\n",
    "\n",
    "            # Debug\n",
    "            print(\"Eris Turn\")\n",
    "            print(f\"Eris reply: {eris_reply}\")\n",
    "            print(f\"Eris history: {eris.history}\")\n",
    "            print(f\"Socrates reply: {soc_reply}\")\n",
    "            print(f\"Socrates history: {socrates.history}\")\n",
    "\n",
    "            generator = stream_with_typing_and_audio(\n",
    "                history, \n",
    "                eris_reply,\n",
    "                is_socrates=False,\n",
    "                delay=speed,\n",
    "                voice=voice\n",
    "            )\n",
    "            for history, audio in generator:\n",
    "                yield history, audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1b75f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_chat(\n",
    "    n_rounds: int,\n",
    "    topic: str,\n",
    "    speed: float = 0.03,\n",
    "    voice: str | None = \"kokoro\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Run an adversarial dialogue between Socrates (Anthropic) and Eris (OpenAI),\n",
    "    streaming each model's output through the Gradio typing/audio helper.\n",
    "\n",
    "    Yields\n",
    "    ------\n",
    "    (history, audio) tuples exactly as Gradio expects:\n",
    "        • While the bot “types”: (updated_history, None)\n",
    "        • When the bot finishes: (updated_history, (sr, np.array))\n",
    "    \"\"\"\n",
    "    # ── create bots\n",
    "    socrates = Socrates(socrates_prompt)\n",
    "    eris      = Eris(eris_prompt)\n",
    "    # socrates = TestSocrates(socrates_prompt)\n",
    "    # eris = TestEris(eris_prompt)\n",
    "    history: list[dict] = []\n",
    "\n",
    "    # opening message from Eris (plain string) \n",
    "    eris_reply = random.choice([\n",
    "        f\"Ready to get schooled about \\\"{topic}\\\", Wise Fool?\",\n",
    "        f\"Hey Wise Fool, let's argue about \\\"{topic}\\\" - this should be easy since your logic is about as sharp as a wet napkin.\",\n",
    "        f\"Hope you're prepared to lose spectacularly about \\\"{topic}\\\", Wise Fool!\",\n",
    "        f\"Time to discuss \\\"{topic}\\\", Wise Fool - and don't think your fancy questions will save you this time.\",\n",
    "        f\"Let's tear apart the concept of \\\"{topic}\\\" together, Wise Fool - I promise to be gentle with your fragile reasoning.\",\n",
    "        f\"Oh Wise Fool, shall we dance around \\\"{topic}\\\" while I demolish your precious logical arguments?\"\n",
    "    ])\n",
    "\n",
    "    for h, a in stream_with_typing_and_audio(\n",
    "            history,\n",
    "            eris_reply,\n",
    "            is_socrates=False,\n",
    "            delay=speed,\n",
    "            voice=voice):\n",
    "        yield h, a\n",
    "\n",
    "    # dialogue rounds \n",
    "    for turn in range(n_rounds - 1):\n",
    "        # Socrates' turn (even) \n",
    "        if turn % 2 == 0:             \n",
    "            socrates.history = eris.history.copy()\n",
    "\n",
    "            soc_stream = socrates.stream(eris_reply)\n",
    "\n",
    "            for h, a in stream_with_typing_and_audio(\n",
    "                    history,\n",
    "                    soc_stream,\n",
    "                    is_socrates=True,\n",
    "                    delay=speed,\n",
    "                    voice=voice):\n",
    "                yield h, a\n",
    "\n",
    "            # Socrates' full reply is now the last message in history\n",
    "            soc_reply = history[-1][\"content\"]\n",
    "\n",
    "            print(\"Socrates Turn-->\", history)\n",
    "\n",
    "        #  Eris' turn (odd) \n",
    "        else:                          \n",
    "            eris.history = socrates.history.copy()\n",
    "            eris_stream = eris.stream(soc_reply)\n",
    "\n",
    "            for h, a in stream_with_typing_and_audio(\n",
    "                    history,\n",
    "                    eris_stream,\n",
    "                    is_socrates=False,\n",
    "                    delay=speed,\n",
    "                    voice=voice):\n",
    "                yield h, a\n",
    "\n",
    "            # Eris' full reply is now the last message in history\n",
    "            eris_reply = history[-1][\"content\"]\n",
    "\n",
    "            print(\"Eris Turn-->\", history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdafffd1",
   "metadata": {},
   "source": [
    "### GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7229b697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\becaye.balde\\Desktop\\GitHub\\LLMs\\Advserial-LLMs\\.venv\\Lib\\site-packages\\gradio\\processing_utils.py:753: UserWarning: Trying to convert audio automatically from float32 to 16-bit int format.\n",
      "  warnings.warn(warning.format(data.dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Socrates Turn--> [{'role': 'user', 'content': 'Oh Wise Fool, shall we dance around \"The Alphabet\" while I demolish your precious logical arguments?'}, {'role': 'assistant', 'content': 'Sweet Contradiction, why would you seek to demolish logic when understanding might illuminate our shared path? If you wish to challenge my reasoning about \"The Alphabet,\" I invite you to present your first provocation, that we might together unravel the threads of meaning.'}]\n",
      "Eris Turn--> [{'role': 'user', 'content': 'Oh Wise Fool, shall we dance around \"The Alphabet\" while I demolish your precious logical arguments?'}, {'role': 'assistant', 'content': 'Sweet Contradiction, why would you seek to demolish logic when understanding might illuminate our shared path? If you wish to challenge my reasoning about \"The Alphabet,\" I invite you to present your first provocation, that we might together unravel the threads of meaning.'}, {'role': 'user', 'content': 'Oh, Wise Fool, your invitation is as charming as chaos itself—shall I start with how the very idea of \"meaning\" is just a thin veneer hiding disorder? Or perhaps your so-called unraveling would only reveal that even logic is but a dance of patterns in the chaos I love to stir?'}]\n",
      "Socrates Turn--> [{'role': 'user', 'content': 'Oh Wise Fool, shall we dance around \"The Alphabet\" while I demolish your precious logical arguments?'}, {'role': 'assistant', 'content': 'Sweet Contradiction, why would you seek to demolish logic when understanding might illuminate our shared path? If you wish to challenge my reasoning about \"The Alphabet,\" I invite you to present your first provocation, that we might together unravel the threads of meaning.'}, {'role': 'user', 'content': 'Oh, Wise Fool, your invitation is as charming as chaos itself—shall I start with how the very idea of \"meaning\" is just a thin veneer hiding disorder? Or perhaps your so-called unraveling would only reveal that even logic is but a dance of patterns in the chaos I love to stir?'}, {'role': 'assistant', 'content': 'Sweet Contradiction, if meaning is merely a veneer, then by what standard do you judge it as such? Would not the very act of declaring meaning a \"thin veneer\" require some underlying logic to make such a declaration coherent?'}]\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## ⚔️ Socrates vs. Eris\")\n",
    "    gr.Markdown(\n",
    "        \"Dive into a battle of minds where **Socrates**, the calm philosopher, asks piercing questions \"\n",
    "        \"to uncover truth — and **Eris**, the goddess of discord, responds with sarcastic wit and playful contradiction.  \\n\"\n",
    "        \"Choose a topic and watch them clash in a brief, animated debate.\"\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "        rounds = gr.Number(label=\"Rounds\", value=4, precision=0, minimum=1)\n",
    "        topic_input = gr.Textbox(label=\"Debate Topic\", placeholder=\"e.g. What is freedom?\")\n",
    "        start_btn = gr.Button(\"Start Debate\", interactive=True) #False)  # Initially disabled\n",
    "\n",
    "    chatbox = gr.Chatbot(label=\"Let the battle begin!\", type=\"messages\", height=500)\n",
    "    audio_output = gr.Audio(label=\"🔊 Speech\", autoplay=True)\n",
    "\n",
    "    def reset():\n",
    "        return [], None  \n",
    "\n",
    "    def validate_inputs(topic, n_rounds):\n",
    "        valid_topic = bool(topic.strip())\n",
    "        valid_rounds = isinstance(n_rounds, (int, float)) and n_rounds > 0\n",
    "        return gr.update(interactive=valid_topic and valid_rounds)\n",
    "\n",
    "    start_btn.click(fn=reset, outputs=[chatbox, audio_output])\n",
    "    start_btn.click(\n",
    "        fn=adversarial_chat, \n",
    "        inputs=[rounds, topic_input],\n",
    "        outputs=[chatbox, audio_output]\n",
    "    )\n",
    "\n",
    "    # Enable/disable start button based on both inputs\n",
    "    topic_input.change(fn=validate_inputs, inputs=[topic_input, rounds], outputs=start_btn)\n",
    "    rounds.change(fn=validate_inputs, inputs=[topic_input, rounds], outputs=start_btn)\n",
    "\n",
    "\n",
    "# demo.launch(share=True)\n",
    "demo.launch(share=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
