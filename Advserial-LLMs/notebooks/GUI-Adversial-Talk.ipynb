{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06cf3063-9f3e-4551-a0d5-f08d9cabb927",
   "metadata": {},
   "source": [
    "# Claude vs GPT\n",
    "\n",
    "**Improvements**\n",
    "- Pause the convo and continue without restarting.\n",
    "- Add paramter to disable streaming in the backend as it is unecessary for our gradio function.\n",
    "- Choose the topic âœ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de23bb9e-37c5-4377-9a82-d7b6c648eeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GitHub\\LLMs\\Advserial-LLMs\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\GitHub\\LLMs\\Advserial-LLMs\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n",
      "d:\\GitHub\\LLMs\\Advserial-LLMs\\.venv\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.gui import adversarial_chat\n",
    "from src.test_chatbot import TestEris, TestSocrates\n",
    "from src.chatbot import Socrates, Eris\n",
    "from src.speak import stream_message, stream_first_message\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import gradio as gr\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "\n",
    "from kokoro import KPipeline\n",
    "from IPython.display import display, Audio\n",
    "# import soundfile as sf\n",
    "# import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c776c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get -qq -y install espeak-ng > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f77b59-2fb1-462a-b90d-78994e4cef33",
   "metadata": {},
   "source": [
    "## Debate: Claude VS GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fb10ba",
   "metadata": {},
   "source": [
    "### Text-to-Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f93404c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GitHub\\LLMs\\Advserial-LLMs\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n",
      "d:\\GitHub\\LLMs\\Advserial-LLMs\\.venv\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "pipeline = KPipeline(lang_code='a', repo_id='hexgrad/Kokoro-82M')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdafffd1",
   "metadata": {},
   "source": [
    "### GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1055de11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_chat(n_rounds, topic, speed=0.01, stop_flag=None):\n",
    "    \"\"\"\n",
    "    Enhanced debate with proper streaming and typing effects.\n",
    "    \"\"\"\n",
    "    # socrates = TestSocrates()\n",
    "    # eris = TestEris()\n",
    "    socrates = Socrates()\n",
    "    eris = Eris()\n",
    "    history = []\n",
    "\n",
    "    # Start the heated debate - use simple streaming for the opening message\n",
    "    eris_options = [\n",
    "        f\"Ready to get schooled about {topic}?, old man?\", \n",
    "        f\"Today's topic is: {topic}. This should be easyâ€”your logic is about as sharp as a wet napkin.\",\n",
    "        f\"Hope you're prepared to lose spectacularly, Socrates. Let us talk about: {topic}\",\n",
    "        f\"Hey Socrates. Wanna argue about: {topic}? It will be fun to see you cry once you have lost.\",\n",
    "    ]\n",
    "    eris_reply = random.choice(eris_options)\n",
    "    print(\"First\", history)\n",
    "    for update in stream_first_message(history, eris_reply, is_socrates=False, delay=speed):\n",
    "        yield update\n",
    "\n",
    "    # Continue with alternating turns using real API streaming\n",
    "    for i in range(n_rounds-1):\n",
    "\n",
    "        print(f\"\\n--- Round {i+1} --->\")\n",
    "        # -> History is automatically updated in the streaming function because it is passed by reference\n",
    "\n",
    "        if i % 2 == 0:\n",
    "            # Socrates takes even turns\n",
    "            socrates.history = eris.history.copy()  # Sync conversation history\n",
    "            for update in stream_message(history, socrates, eris_reply, is_socrates=True, delay=speed):\n",
    "                yield update\n",
    "            soc_reply = history[-1][\"content\"]\n",
    "            \n",
    "        else:\n",
    "            #  Eris takes odd turns\n",
    "            eris.history = socrates.history.copy()  # Sync conversation history\n",
    "            for update in stream_message(history, eris, soc_reply, is_socrates=False, delay=speed):\n",
    "                yield update\n",
    "            eris_reply = history[-1][\"content\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7229b697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GitHub\\LLMs\\Advserial-LLMs\\.venv\\Lib\\site-packages\\gradio\\processing_utils.py:753: UserWarning: Trying to convert audio automatically from float32 to 16-bit int format.\n",
      "  warnings.warn(warning.format(data.dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Round 1 --->\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "*adjusts toga and looks at Eris with a calm, penetrating gaze*\n",
       "\n",
       "Ah, Eris, goddess of chaos. I see you wish to engage in a dialogue about freedom. But true freedom is not mere disorder or rebellion, but a carefully considered state of being guided by reason and wisdom. Freedom without understanding is like an unguided chariot - it will inevitably crash.\n",
       "\n",
       "Shall we explore what freedom truly means? I am prepared to examine this concept through rational discourse, if you are willing to listen and think critically.\n",
       "\n",
       "*raises an eyebrow, waiting for her response*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Round 2 --->\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Oh, Socrates, always the philosopher, trying to turn chaos into some kind of organized lecture. Please, spare me your \"rational discourse.\" Freedom, to me, is breaking free from your endless chains of logic and reason, and just doing what feels rightâ€”chaos, pure and simple! \n",
       "\n",
       "Wisdom? Please, you're dressed in robes and arguing about order while the world is a playground for my delightful disorder. Who needs your so-called \"understanding\" when you can revel in unpredictability? That's real freedomâ€”unshackled by your drab rules. You call it chaos? I call it liberation from your boring, constrictive truths.\n",
       "\n",
       "Now, tell me againâ€”what's so wise about blindly following rules? Because Iâ€™d rather dance with disorder than wallow in your antiquated ideas!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## âš”ï¸ Socrates vs. Eris\")\n",
    "    gr.Markdown(\n",
    "        \"Dive into a battle of minds where **Socrates**, the calm philosopher, asks piercing questions \"\n",
    "        \"to uncover truth â€” and **Eris**, the goddess of discord, responds with sarcastic wit and playful contradiction.  \\n\"\n",
    "        \"Choose a topic and watch them clash in a brief, animated debate.\"\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "        rounds = gr.Number(label=\"Rounds\", value=4, precision=0, minimum=1)\n",
    "        topic_input = gr.Textbox(label=\"Debate Topic\", placeholder=\"e.g. What is freedom?\")\n",
    "        start_btn = gr.Button(\"Start Debate\", interactive=False)  # Initially disabled\n",
    "\n",
    "    chatbox = gr.Chatbot(label=\"Let the battle begin!\", type=\"messages\", height=500)\n",
    "    audio_output = gr.Audio(label=\"ðŸ—£ï¸\", autoplay=True, visible=True)\n",
    "\n",
    "    def reset_chat():\n",
    "        return [], None\n",
    "\n",
    "    def validate_inputs(topic, n_rounds):\n",
    "        valid_topic = bool(topic.strip())\n",
    "        valid_rounds = isinstance(n_rounds, (int, float)) and n_rounds > 0\n",
    "        return gr.update(interactive=valid_topic and valid_rounds)\n",
    "\n",
    "    # Hook to clear previous chat/audio\n",
    "    start_btn.click(fn=reset_chat, outputs=[chatbox, audio_output])\n",
    "\n",
    "    # Launch the debate\n",
    "    start_btn.click(fn=adversarial_chat,\n",
    "                    inputs=[rounds, topic_input],\n",
    "                    outputs=[chatbox, audio_output])\n",
    "\n",
    "    # Enable/disable start button based on both inputs\n",
    "    topic_input.change(fn=validate_inputs, inputs=[topic_input, rounds], outputs=start_btn)\n",
    "    rounds.change(fn=validate_inputs, inputs=[topic_input, rounds], outputs=start_btn)\n",
    "\n",
    "\n",
    "demo.launch(share=False)\n",
    "# demo.launch(share=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
